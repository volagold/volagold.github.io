<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="author" content="Fei Li"><meta name="description" content="data science and programming blogs"><meta name="keywords" content="mathematics,data science,machine learning,deep learning,artificial intelligence,scientific computing,programming,python,julia"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@lifeitech"><meta name="twitter:creator" content="@lifeitech"><meta property="og:image" content="https://volagold.github.io/assets/imgs/website-post.jpg"><meta property="og:title" content="volagold.github.io"><meta property="og:description" content="data science and programming blogs"><meta property="og:url" content="https://volagold.github.io"><meta property="og:type" content="article"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Sequence Labeling with HMM and CRF" /><meta property="og:locale" content="en" /><meta name="description" content="Sequence labeling is a classical task in natural language processing. In this task, a program is expected to recognize certain information given a piece of text. This is challenging, because even though input data items in real application can look similar, there may be small variations here and there that are comprehensible to humans but nevertheless are not present in other data items, so that it is difficult to use hard coded rules for solving the problem." /><meta property="og:description" content="Sequence labeling is a classical task in natural language processing. In this task, a program is expected to recognize certain information given a piece of text. This is challenging, because even though input data items in real application can look similar, there may be small variations here and there that are comprehensible to humans but nevertheless are not present in other data items, so that it is difficult to use hard coded rules for solving the problem." /><link rel="canonical" href="https://volagold.github.io/posts/sequence-labeling/" /><meta property="og:url" content="https://volagold.github.io/posts/sequence-labeling/" /><meta property="og:site_name" content="volagold.github.io" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-03-26T09:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Sequence Labeling with HMM and CRF" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-04T09:53:55+08:00","datePublished":"2022-03-26T09:00:00+08:00","description":"Sequence labeling is a classical task in natural language processing. In this task, a program is expected to recognize certain information given a piece of text. This is challenging, because even though input data items in real application can look similar, there may be small variations here and there that are comprehensible to humans but nevertheless are not present in other data items, so that it is difficult to use hard coded rules for solving the problem.","headline":"Sequence Labeling with HMM and CRF","mainEntityOfPage":{"@type":"WebPage","@id":"https://volagold.github.io/posts/sequence-labeling/"},"url":"https://volagold.github.io/posts/sequence-labeling/"}</script><title>Sequence Labeling with HMM and CRF | volagold.github.io</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/imgs/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/imgs/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/imgs/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/imgs/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/imgs/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="volagold.github.io"><meta name="application-name" content="volagold.github.io"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/imgs/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.1.3/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.min.css"> <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/38937278" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">volagold.github.io</a></div><div class="site-subtitle">data science and programming blogs</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <span style="font-size: 1.2em;">üè†</span> <span>Home</span> </a><li class="nav-item"> <a href="/notes/" class="nav-link"> <span style="font-size: 1.2em;">üìï</span> <span>Notes</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <span style="font-size: 1.2em;">üìÅ</span> <span>Categories</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <span style="font-size: 1.2em;">üîñ</span> <span>Tags</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <span style="font-size: 1.2em;">üì¶</span> <span>Archives</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <span style="font-size: 1.2em;">‚ö°</span> <span>About</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://www.linkedin.com/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://github.com/volagold" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Sequence Labeling with HMM and CRF</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@lifeitech"><meta name="twitter:creator" content="@lifeitech"><meta property="og:image" content="https://volagold.github.io/assets/imgs/seq-labeling.jpg"><meta property="og:title" content="Sequence Labeling with HMM and CRF"><meta property="og:description" content="<blockquote><p>Sequence labeling is a classical task in natural language processing. In this task, a program is expected to recognize certain information given a piece of text. This is challenging, because even though input data items in real application can look similar, there may be small variations here and there that are comprehensible to humans but nevertheless are not present in other data items, so that it is difficult to use hard coded rules for solving the problem.</p></blockquote>"><meta property="og:url" content="https://volagold.github.io/posts/sequence-labeling/"><meta property="og:type" content="article"> <img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 800 500'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/imgs/seq-labeling.jpg" class="preview-img bg" alt="Sequence Labeling with HMM and CRF" width="800" height="500" ><h1 data-toc-skip>Sequence Labeling with HMM and CRF</h1><div class="post-meta text-muted"><div> By <em> <a href="https://volagold.github.io">volagold</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2022-03-26 09:00:00 +0800" data-toggle="tooltip" data-placement="bottom" title="Sat, Mar 26, 2022, 9:00 AM +0800" >Mar 26, 2022</em> </span> <span> Updated <em class="timeago" date="2023-04-04 09:53:55 +0800 " data-toggle="tooltip" data-placement="bottom" title="Tue, Apr 4, 2023, 9:53 AM +0800" >Apr 4, 2023</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1063 words"> <em>7 min</em> read</span></div></div></div><div class="post-content js-toc-content"><blockquote><p>Sequence labeling is a classical task in natural language processing. In this task, a program is expected to recognize certain information given a piece of text. This is challenging, because even though input data items in real application can look similar, there may be small variations here and there that are comprehensible to humans but nevertheless are not present in other data items, so that it is difficult to use hard coded rules for solving the problem.</p></blockquote><p>Sequence labeling is the task in which we assign each word $x_i$ in an input word sequence a label $y_i$, so that the output sequence $Y$ has the same length as the input sequence $X$. Two specific scenarios are:</p><ul><li>Parts of speech tagging. Parts of speech refer to the grammatical property of a word: noun, verb, pronoun, preposition, adverb, conjunction, participle, and article.<li>Named entity recognition (NER). In NER we would like to extract structured information from unstructured text, like name, location, school, time, price and so on. The named entity recognition problem can be converted to a sequence labeling problem, by giving each word a label. Anything outside of interest gets a label like ‚ÄúO‚Äù.</ul><p><img data-proofer-ignore data-src="/assets/imgs/ner-illustration2.png" alt="Illustration of Named entity recognition (NER) - politically exposed person (PEP)" /> <em>Named entity recognition (NER) concerns extracting structured information from unstructured text data. Shown in the figure are resume items of two Chinese <a href="https://en.wikipedia.org/wiki/Politically_exposed_person">politically exposed persons (PEP)</a>, where their personal info could be extracted for anti money laundering purposes.</em></p><p>We introduce two models for solving sequence labeling problem, the Hidden Markov Model (HMM) and the Conditional Random Field (CRF). Both are probabilistic models that make predictions by selecting tags/labels with largest probabilities. Don‚Äôt be intimidated by the two fancy names. They are something that you are probably already familiar with. HMM corresponds to generative modeling or Bayes‚Äô rule, and CRF corresponds to discriminative modeling or logistic regression. The difference is that, since inputs and outputs come in sequence, rather than treating each input and output element in isolation, previous inputs and outputs are taken into account when making predictions about the current output.</p><h2 id="hidden-markov-model-hmm">Hidden Markov Model (HMM)<a href="#hidden-markov-model-hmm"><i class="fas fa-hashtag"></i></a></h2></h2><p>HMM is generative. Given an input sequence $X=x_1\ldots x_n$, the prediction about their labels $Y=y_1\ldots y_n$ is</p>\[\begin{split} Y^* &amp;= \mathop{\mathrm{argmax}}_{Y}\mathbb{P}(Y\mid X)\\[1em] &amp;= \mathop{\mathrm{argmax}}_{Y}\frac{\mathbb{P}(X\mid Y)\mathbb{P}(Y)}{\mathbb{P}(X)}\\[1em] &amp;= \mathop{\mathrm{argmax}}_{Y}\mathbb{P}(X\mid Y)\mathbb{P}(Y)\\ &amp;= \mathop{\mathrm{argmax}}_{Y}\prod_{i=1}^n\mathbb{P}(x_i\mid y_i)\mathbb{P}(y_i\mid y_{i-1}). \end{split}\]<p>Namely, To select the most probable output sequence $Y$, we select $Y$ that makes text sequence $X$ that we observe most probable. There are two assumptions:</p><ul><li><p>Markov assumption: the probability of being in state $y_i$ only depends on the last state: $\mathbb{P}(y_i\mid y_{1},\ldots,y_{i-1})=\mathbb{P}(y_i\mid y_{i-1})$, so that $\mathbb{P}(y_1\ldots y_n) = \prod_{i=1}^n\mathbb{P}(y_i\mid y_{i-1})$</p><li><p>Output independence: the probability of observing $x_i$ only depends on the hidden state $y_i$, but not on previous words or hidden states.</p></ul><p>The name ‚ÄúHidden Markov Model‚Äù comes from the rhetoric that labels are like a hidden Markov chain with certain states and transition probabilities among them. These states ‚Äúemit‚Äù word sequences (text data).</p><p>MLE estimations of the probabilities in the above equation are frequencies in the training corpus:</p>\[\mathbb{P}(x_i\mid y_i) = \frac{\#(x_i,y_i)}{\# y_i}.\] \[\mathbb{P}(y_i\mid y_{i-1}) = \frac{\#(y_i, y_{i-1})}{\# y_{i-1}}.\]<h3 id="the-viterbi-algorithm">The Viterbi algorithm<a href="#the-viterbi-algorithm"><i class="fas fa-hashtag"></i></a></h3></h3><p>Now, to make inference in HMM, we have to select the best label \(y_s^*\) among a set of states \(\{y_1,\ldots,y_S\}\) at each time step $i=1,\ldots,n$. This requires some work. We achieve this, by calculating and saving the maximum value for each state \(y_s\) in \(\{y_1,\ldots,y_S\}\) at each step $i$, denoted by \(v(i, y_s)\), as well as the pointer to the state at step $i-1$ that leads to this maximum value. At the final step, we select the label or state \(y_n^*\) with maximal value for \(v(n, y_s)\). Then we follow its pointer to backtrack from this label/state to the previous label/state \(y_{n-1}^*\), until we reach the beginning, to get the optimal output sequence \(y_1^*,\ldots,y_n^*\). Yes, here we are using a dynamic programming algorithm to solve a <em>graph maximization problem</em>. It is called the <em>Viterbi algorithm</em>.</p><p>In the course of the algorithm, we populate a table with value $v(i, y_s)$ and a pointer. The Bellman equation is</p>\[v(i, y_s) = \max_{y\in\{y_1,\ldots,y_S\}} v(i-1, y)\cdot \mathbb{P}(x_i\mid y_s)\cdot \mathbb{P}(y_s\mid y).\]<p>See Figure 1 for an illustration of the algorithm. As it‚Äôs clear from the description above, its running time is \(\vert S\vert^2\cdot n\). For a sequence \(Y=y_1\ldots y_n\) with length \(n\) where each \(y_i\) can be any element in \(\{y_1,\ldots,y_S\}\), there are \(\vert S\vert^n\) such paths in total. Without the Viterbi algorithm, finding the argmax would require an exponential amount of computation. With savings of intermediate results in memory, we are able to reduce a large amount of computation.</p><p><img data-proofer-ignore data-src="/assets/imgs/viterbi.png" alt="Hiden Markov Model (HMM) - Illustration of the Viterbi Algorithm" /> <em>Figure 1: Illustration of the Viterbi Algorithm for solving Hidden Markov Model (HMM). The model is a generative model. To select the most probable output sequence $Y$, we select $Y$ that makes text sequence $X$ most probable.</em></p><h2 id="conditional-random-field-crf">Conditional Random Field (CRF)<a href="#conditional-random-field-crf"><i class="fas fa-hashtag"></i></a></h2></h2><p>CRF is discriminative. It attempts to directly model $\mathbb{P}(Y\mid X)$ with multi-class logistic regression. The difference with vanilla logistic regression is that, not only isolated data points $(x_i,y_i)$, but also $y_{i-1}$, the previous label, are incorporated into features. Let $\mathcal{Y}$ denote the set of all possible output sequences $Y$ with length $n$, which has an exponential size $|S|^n$. The model is</p>\[\mathbb{P}(Y\mid X) = \dfrac{\exp\left(\sum\limits_{k=1}^Kw_kF_k(Y,X)\right)}{ \sum\limits_{Y'\in\mathcal{Y}}\exp\left(\sum\limits_{k=1}^Kw_kF_k(Y',X)\right)}.\]<p>Or, write the denominator in the last equation as $Z(X)$,</p>\[\mathbb{P}(Y\mid X) = \frac{1}{Z(X)}\exp\left(\sum_{k=1}^Kw_kF_k(Y,X)\right).\]<p>The $K$ features $F_1(Y,X),\ldots,F_K(Y,X)$ are called global features. In <em>linear chain</em> CRF, each global feature is a summation of $n$ local features $f_k(\cdot,\,i), i=1,\ldots,n$, where each $f_k(\cdot,\,i)$ could be an indicator function:</p>\[F_k(Y,X) = \sum_{i=1}^nf_k(y_{i-1}, y_{i}, X, i).\]<p>Training is done by MLE, thanks to the fact that $n$ is not too large and the normalizing constant $Z(X)$ can be computed in reasonable time. For inference,</p>\[\begin{split} Y^* &amp;= \mathop{\mathrm{argmax}}_{Y}\mathbb{P}(Y\mid X)\\ &amp;= \mathop{\mathrm{argmax}}_{Y}\sum_{k=1}^Kw_kF_k(Y,X)\\ &amp;= \mathop{\mathrm{argmax}}_{Y}\sum_{k=1}^Kw_k\sum_{i=1}^nf_k(y_{i-1}, y_{i}, X, i)\\ &amp;= \mathop{\mathrm{argmax}}_{Y}\sum_{i=1}^n\sum_{k=1}^Kw_kf_k(y_{i-1}, y_{i}, X, i),\\ \end{split}\]<p>and again we use the Viterbi algorithm for this sequence maximization problem.</p><h2 id="summary">Summary<a href="#summary"><i class="fas fa-hashtag"></i></a></h2></h2><p>In this post, we introduced two models for solving sequence labeling problem in NLP: Hidden Markov Model (HMM) and Conditional Random Field (CRF). HMM maximizes $\mathbb{P}(Y\mid X)$ by maximizing $\mathbb{P}(X\mid Y)\mathbb{P}(Y)$, while CRF models $\mathbb{P}(Y\mid X)$ with features. Both models take $y_{i-1}$ into account when calculating probability on $y_i$. Both use the Viterbi algorithm for deriving the optimal output sequence $Y=y_1\ldots y_n$.</p><hr /><p>Cite as:</p><div class="language-bibtex highlighter-rouge"><div class="code-header"> <span label-text="Bibtex"><i class="fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="nc">@article</span><span class="p">{</span><span class="nl">lifei2022hmm</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">"Sequence Labeling with HMM and CRF"</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">"Li, Fei"</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">"https://volagold.github.io"</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">"2022"</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">"https://volagold.github.io/posts/sequence-labeling/"</span>
<span class="p">}</span>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/nlp/" class="post-tag no-text-decoration" >nlp</a> <a href="/tags/ner/" class="post-tag no-text-decoration" >ner</a> <a href="/tags/hmm/" class="post-tag no-text-decoration" >hmm</a> <a href="/tags/crf/" class="post-tag no-text-decoration" >crf</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Sequence Labeling with HMM and CRF - volagold.github.io&url=https://volagold.github.io/posts/sequence-labeling/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Sequence Labeling with HMM and CRF - volagold.github.io&u=https://volagold.github.io/posts/sequence-labeling/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Sequence Labeling with HMM and CRF - volagold.github.io&url=https://volagold.github.io/posts/sequence-labeling/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://volagold.github.io/posts/sequence-labeling/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/app-development/">app-development</a> <a class="post-tag" href="/tags/database/">database</a> <a class="post-tag" href="/tags/generative-model/">generative-model</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/react/">react</a> <a class="post-tag" href="/tags/web-development/">web-development</a> <a class="post-tag" href="/tags/attention/">attention</a> <a class="post-tag" href="/tags/big-data/">big-data</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" class="js-toc"></nav></div><script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.min.js"></script> <script> tocbot.init({ tocSelector: '.js-toc', contentSelector: '.js-toc-content', headingSelector: 'h1, h2, h3', hasInnerContainers: true, }); </script></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/rnn/"><div class="card-body"> <em class="timeago small" date="2022-04-08 22:00:00 +0800" >Apr 8, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>RNN, LSTM and GRU</h3><div class="text-muted small"><p> In this post we introduce the recurrent neural network (RNN) model in natural language processing (NLP), as well as two improvements over it, long short-term memories (LSTM) and gated recurrent ...</p></div></div></a></div><div class="card"> <a href="/posts/attention-and-transformers/"><div class="card-body"> <em class="timeago small" date="2022-04-11 22:30:00 +0800" >Apr 11, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Attention and Transformers</h3><div class="text-muted small"><p> In recent years, Transformer-based models are trending and are quickly taking up not only the field of NLP, but also computer vision and many other fields in AI. In this post, we give a tutorial...</p></div></div></a></div><div class="card"> <a href="/posts/nlp-prob-ngram/"><div class="card-body"> <em class="timeago small" date="2022-03-05 16:20:00 +0800" >Mar 5, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Natural Language Processing, Probabilities and the n-gram Model</h3><div class="text-muted small"><p> This is the first one of a series of posts on Natural Language Processing (NLP). We give an introduction to the subject, mention two model evaluation methods, see how to assign probabilities to ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/embedding-and-word2vec/" class="btn btn-outline-primary" prompt="Older"><p>Embeddings and the word2vec Method</p></a> <a href="/posts/rnn/" class="btn btn-outline-primary" prompt="Newer"><p>RNN, LSTM and GRU</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> ¬© 2025 <a href="https://volagold.github.io">volagold</a> <span></span></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/app-development/">app-development</a> <a class="post-tag" href="/tags/database/">database</a> <a class="post-tag" href="/tags/generative-model/">generative-model</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/react/">react</a> <a class="post-tag" href="/tags/web-development/">web-development</a> <a class="post-tag" href="/tags/attention/">attention</a> <a class="post-tag" href="/tags/big-data/">big-data</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdnjs.cloudflare.com/ajax/libs/simple-jekyll-search/1.9.2/simple-jekyll-search.min.js" referrerpolicy="no-referrer"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" referrerpolicy="no-referrer"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js" integrity="sha512-IsNh5E3eYy3tr/JiX2Yx4vsCujtkhwl7SLqgnwLNgf04Hrt9BT9SXlLlZlWx+OK4ndzAoALhsMNcCmkggjZB1w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { tags: 'ams', inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ], processEscapes: true } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.1/es5/tex-mml-chtml.min.js" integrity="sha512-lt3EkmQb16BgAXR0iCk+JUJyDFmS9NZEMXCXK169qQoWcXu9CS4feejtxkjjUruw/Y0XfL1qxh41xVQPvCxM1A==" crossorigin="anonymous" referrerpolicy="no-referrer"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.1.3/js/bootstrap.bundle.min.js" integrity="sha512-pax4MlgXjHEPfCwcJLQhigY7+N8rt6bVvWLFyUMuxShv170X53TRzGPmPkZmGBhk+jikR8WBM4yl7A9WMHHqvg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
